{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting loan default\n",
    "\n",
    "Our goal is to compare a variety of models for predicting loan default from a consumer's loan history, aiming to maximize accuracy on a chosen test set with little regard for other factors such as model interpretability, training time, etc.\n",
    "\n",
    "### Data\n",
    "\n",
    "Data comes from LendingClub and has been prepared and saved in 'data_final.csv'.\n",
    "We use data from before 2014 for training, and use 2014 data as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.optimize import minimize, LinearConstraint\n",
    "\n",
    "data = pd.read_csv('data_final.csv', parse_dates=['issue_d'], index_col=0)\n",
    "\n",
    "train = data.loc[data.issue_d < 'January 2014']\n",
    "test = data.loc[data.issue_d > 'December 2013']\n",
    "\n",
    "X_cols_full = [c for c in train.columns if not c in ('Default', 'issue_d')]\n",
    "X_cols_minusCat = [c for c in X_cols_full if c != 'home_ownership']\n",
    "X_cols = X_cols_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbors model\n",
    "\n",
    "The parameters we want to tune here are k (the number of neighbors to check for each point), the distance metric, and the weighting scheme. In addition, there is a categorical variable ('home_ownership') which has been coded as an integer (ranking the categories by decreasing probability of default) and we want to test whether we should include this variable.\n",
    "In principle each of these parameters may have an independent effect on model accuracy, so we can test every combination (within some reasonable range of parameters). \n",
    "\n",
    "As an experiment, we use a small sample test set to test every possible model where the parameters lie in the following ranges:\n",
    "1. $k \\in \\{4, 8, 12\\}$\n",
    "2. Four distance metrics: Minkowski metrics for $p \\in \\{1, 2, 4\\}$ and Chebyshev metric\n",
    "3. Including/excluding the categorical variable home_ownership\n",
    "4. Equal weights or inverse-distance weights\n",
    "\n",
    "In total, this gives us $3 \\cdot 4 \\cdot 2 \\cdot 2 = 48$ models to check. We'll compute the accuracy of each model, store the parameters and accuracy in a data frame, and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample to test models\n",
    "train_sample = train.sample(n=5000, replace=False)\n",
    "test_sample = test.sample(n=5000, replace=False)\n",
    "\n",
    "X_train_full = train_sample[X_cols_full]\n",
    "X_test_full = test_sample[X_cols_full]\n",
    "scaler_full = MinMaxScaler()\n",
    "X_train_full = scaler_full.fit_transform(X_train_full)\n",
    "X_test_full = scaler_full.transform(X_test_full)\n",
    "\n",
    "X_train_minusCat = train_sample[X_cols_minusCat]\n",
    "X_test_minusCat = test_sample[X_cols_minusCat]\n",
    "scaler_minusCat = MinMaxScaler()\n",
    "X_train_minusCat = scaler_minusCat.fit_transform(X_train_minusCat)\n",
    "X_test_minusCat = scaler_minusCat.transform(X_test_minusCat)\n",
    "\n",
    "y_train, y_test = train_sample.Default, test_sample.Default\n",
    "\n",
    "# Wrapper for interfacing with sklearn\n",
    "class KnnModel:\n",
    "    def __init__(self, metric, metric_label, k, equalWeights, includeCategorical, p=None):\n",
    "        \"\"\"Compute knn model, score, and dict for row in dataframe\"\"\"\n",
    "        if includeCategorical:\n",
    "            X_train, X_test = X_train_full, X_test_full\n",
    "        else:\n",
    "            X_train, X_test = X_train_minusCat, X_test_minusCat\n",
    "        if equalWeights:\n",
    "            weights = 'uniform'\n",
    "        else:\n",
    "            weights = 'distance'\n",
    "            \n",
    "        if p:\n",
    "            self.model = KNeighborsClassifier(\n",
    "                n_neighbors=k,\n",
    "                metric=metric,\n",
    "                p=p,\n",
    "                weights=weights\n",
    "            ).fit(X_train, y_train)\n",
    "        else:\n",
    "            self.model = KNeighborsClassifier(\n",
    "                n_neighbors=k,\n",
    "                metric=metric,\n",
    "                weights=weights\n",
    "            ).fit(X_train, y_train)\n",
    "        \n",
    "        self.score = self.model.score(X_test, y_test)\n",
    "        self.rowDict = {\n",
    "            'metric': metric_label, \n",
    "            'categorical': includeCategorical, \n",
    "            'equal': equalWeights,\n",
    "            'k': k, \n",
    "            'score': self.score\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing parameters: manhattan, True, True, 4\n",
      "Score = 0.8578\n",
      "Computing parameters: manhattan, True, True, 8\n",
      "Score = 0.8604\n",
      "Computing parameters: manhattan, True, True, 12\n",
      "Score = 0.8616\n",
      "Computing parameters: manhattan, True, False, 4\n",
      "Score = 0.838\n",
      "Computing parameters: manhattan, True, False, 8\n",
      "Score = 0.859\n",
      "Computing parameters: manhattan, True, False, 12\n",
      "Score = 0.8612\n",
      "Computing parameters: manhattan, False, True, 4\n",
      "Score = 0.858\n",
      "Computing parameters: manhattan, False, True, 8\n",
      "Score = 0.8596\n",
      "Computing parameters: manhattan, False, True, 12\n",
      "Score = 0.8612\n",
      "Computing parameters: manhattan, False, False, 4\n",
      "Score = 0.8348\n",
      "Computing parameters: manhattan, False, False, 8\n",
      "Score = 0.8558\n",
      "Computing parameters: manhattan, False, False, 12\n",
      "Score = 0.8604\n",
      "Computing parameters: euclidean, True, True, 4\n",
      "Score = 0.8574\n",
      "Computing parameters: euclidean, True, True, 8\n",
      "Score = 0.86\n",
      "Computing parameters: euclidean, True, True, 12\n",
      "Score = 0.8612\n",
      "Computing parameters: euclidean, True, False, 4\n",
      "Score = 0.8356\n",
      "Computing parameters: euclidean, True, False, 8\n",
      "Score = 0.8554\n",
      "Computing parameters: euclidean, True, False, 12\n",
      "Score = 0.86\n",
      "Computing parameters: euclidean, False, True, 4\n",
      "Score = 0.8556\n",
      "Computing parameters: euclidean, False, True, 8\n",
      "Score = 0.8596\n",
      "Computing parameters: euclidean, False, True, 12\n",
      "Score = 0.861\n",
      "Computing parameters: euclidean, False, False, 4\n",
      "Score = 0.8348\n",
      "Computing parameters: euclidean, False, False, 8\n",
      "Score = 0.8558\n",
      "Computing parameters: euclidean, False, False, 12\n",
      "Score = 0.8608\n",
      "Computing parameters: minkowski (p=4), True, True, 4\n",
      "Score = 0.8566\n",
      "Computing parameters: minkowski (p=4), True, True, 8\n",
      "Score = 0.8598\n",
      "Computing parameters: minkowski (p=4), True, True, 12\n",
      "Score = 0.8614\n",
      "Computing parameters: minkowski (p=4), True, False, 4\n",
      "Score = 0.834\n",
      "Computing parameters: minkowski (p=4), True, False, 8\n",
      "Score = 0.8558\n",
      "Computing parameters: minkowski (p=4), True, False, 12\n",
      "Score = 0.861\n",
      "Computing parameters: minkowski (p=4), False, True, 4\n",
      "Score = 0.8558\n",
      "Computing parameters: minkowski (p=4), False, True, 8\n",
      "Score = 0.8602\n",
      "Computing parameters: minkowski (p=4), False, True, 12\n",
      "Score = 0.8614\n",
      "Computing parameters: minkowski (p=4), False, False, 4\n",
      "Score = 0.8302\n",
      "Computing parameters: minkowski (p=4), False, False, 8\n",
      "Score = 0.8566\n",
      "Computing parameters: minkowski (p=4), False, False, 12\n",
      "Score = 0.8606\n",
      "Computing parameters: chebyshev, True, True, 4\n",
      "Score = 0.8556\n",
      "Computing parameters: chebyshev, True, True, 8\n",
      "Score = 0.8598\n",
      "Computing parameters: chebyshev, True, True, 12\n",
      "Score = 0.861\n",
      "Computing parameters: chebyshev, True, False, 4\n",
      "Score = 0.831\n",
      "Computing parameters: chebyshev, True, False, 8\n",
      "Score = 0.8562\n",
      "Computing parameters: chebyshev, True, False, 12\n",
      "Score = 0.8598\n",
      "Computing parameters: chebyshev, False, True, 4\n",
      "Score = 0.8562\n",
      "Computing parameters: chebyshev, False, True, 8\n",
      "Score = 0.8612\n",
      "Computing parameters: chebyshev, False, True, 12\n",
      "Score = 0.8612\n",
      "Computing parameters: chebyshev, False, False, 4\n",
      "Score = 0.834\n",
      "Computing parameters: chebyshev, False, False, 8\n",
      "Score = 0.8578\n",
      "Computing parameters: chebyshev, False, False, 12\n",
      "Score = 0.8606\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Computing model scores\n",
    "metrics = ['minkowski', 'minkowski', 'minkowski', 'chebyshev']\n",
    "ps = [1, 2, 4, None]\n",
    "metric_labels = ['manhattan', 'euclidean', 'minkowski (p=4)', 'chebyshev']\n",
    "krange = [4, 8, 12]\n",
    "            \n",
    "rows = []\n",
    "for metric, p, metric_label in zip(metrics, ps, metric_labels):\n",
    "    for includeCategorical in (True, False):\n",
    "        for equalWeights in (True, False):\n",
    "            for k in krange:\n",
    "                print('Computing parameters: ' + \\\n",
    "                      ', '.join([metric_label, str(includeCategorical), str(equalWeights), str(k)]))\n",
    "                km = KnnModel(metric, metric_label, k, equalWeights, includeCategorical, p)\n",
    "                print('Score = ' + str(km.score))\n",
    "                rows.append(km.rowDict)\n",
    "\n",
    "dfModels  = pd.DataFrame(columns=['metric', 'categorical', 'equal', 'k', 'score'])\n",
    "for i, row in enumerate(rows):\n",
    "    dfModels.loc[i] = row\n",
    "dfModels.to_csv('knn_test_model_scores.csv')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a ranking for all parameters, let's take the top 5 models, run them for a larger portion of the test set, and see which has the highest accuracy. To check that our ranking is reasonable, we'll also test the worst 5 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'minkowski', 'p': 4, 'metric_label': 'minkowski (p=4)', 'categorical': False, 'equal': False, 'k': 4}\n",
      "Score = 0.8342666666666667\n",
      "{'metric': 'chebyshev', 'p': None, 'metric_label': 'chebyshev', 'categorical': True, 'equal': False, 'k': 4}\n",
      "Score = 0.8366666666666667\n",
      "{'metric': 'chebyshev', 'p': None, 'metric_label': 'chebyshev', 'categorical': False, 'equal': False, 'k': 4}\n",
      "Score = 0.8359333333333333\n",
      "{'metric': 'minkowski', 'p': 4, 'metric_label': 'minkowski (p=4)', 'categorical': True, 'equal': False, 'k': 4}\n",
      "Score = 0.8358\n",
      "{'metric': 'minkowski', 'p': 1, 'metric_label': 'manhattan', 'categorical': False, 'equal': False, 'k': 4}\n",
      "Score = 0.8310666666666666\n",
      "{'metric': 'chebyshev', 'p': None, 'metric_label': 'chebyshev', 'categorical': False, 'equal': True, 'k': 8}\n",
      "Score = 0.8623333333333333\n",
      "{'metric': 'chebyshev', 'p': None, 'metric_label': 'chebyshev', 'categorical': False, 'equal': True, 'k': 12}\n",
      "Score = 0.8633333333333333\n",
      "{'metric': 'minkowski', 'p': 4, 'metric_label': 'minkowski (p=4)', 'categorical': True, 'equal': True, 'k': 12}\n",
      "Score = 0.8639333333333333\n",
      "{'metric': 'minkowski', 'p': 4, 'metric_label': 'minkowski (p=4)', 'categorical': False, 'equal': True, 'k': 12}\n",
      "Score = 0.8634\n",
      "{'metric': 'minkowski', 'p': 1, 'metric_label': 'manhattan', 'categorical': True, 'equal': True, 'k': 12}\n",
      "Score = 0.8638\n",
      "            metric categorical  equal   k     score rank\n",
      "0  minkowski (p=4)       False  False   4  0.834267   -5\n",
      "1        chebyshev        True  False   4  0.836667   -4\n",
      "2        chebyshev       False  False   4  0.835933   -3\n",
      "3  minkowski (p=4)        True  False   4  0.835800   -2\n",
      "4        manhattan       False  False   4  0.831067   -1\n",
      "5        chebyshev       False   True   8  0.862333    1\n",
      "6        chebyshev       False   True  12  0.863333    2\n",
      "7  minkowski (p=4)        True   True  12  0.863933    3\n",
      "8  minkowski (p=4)       False   True  12  0.863400    4\n",
      "9        manhattan        True   True  12  0.863800    5\n"
     ]
    }
   ],
   "source": [
    "dfModels = pd.read_csv('knn_test_model_scores.csv', index_col=0)\n",
    "dfModels.sort_values(by=['score'], inplace=True)\n",
    "\n",
    "# Get larger sample\n",
    "train_sample = train.sample(n=5000, replace=False)\n",
    "test_sample = test.sample(n=15000, replace=False)\n",
    "\n",
    "X_train_full = train_sample[X_cols_full]\n",
    "X_test_full = test_sample[X_cols_full]\n",
    "scaler_full = MinMaxScaler()\n",
    "X_train_full = scaler_full.fit_transform(X_train_full)\n",
    "X_test_full = scaler_full.transform(X_test_full)\n",
    "\n",
    "X_train_minusCat = train_sample[X_cols_minusCat]\n",
    "X_test_minusCat = test_sample[X_cols_minusCat]\n",
    "scaler_minusCat = MinMaxScaler()\n",
    "X_train_minusCat = scaler_minusCat.fit_transform(X_train_minusCat)\n",
    "X_test_minusCat = scaler_minusCat.transform(X_test_minusCat)\n",
    "\n",
    "y_train, y_test = train_sample.Default, test_sample.Default\n",
    "\n",
    "# Compute models on larger sample\n",
    "metric_map = {\n",
    "    'minkowski (p=4)': ('minkowski', 4),\n",
    "    'manhattan': ('minkowski', 1),\n",
    "    'euclidean': ('minkowski', 2),\n",
    "    'chebyshev': ('chebyshev', None)\n",
    "}\n",
    "def modelFromDfRow(row):\n",
    "    params = {\n",
    "        'metric': metric_map[row.metric][0],\n",
    "        'p': metric_map[row.metric][1],\n",
    "        'metric_label': row.metric,\n",
    "        'categorical': row.categorical,\n",
    "        'equal': row.equal,\n",
    "        'k': row.k\n",
    "    }\n",
    "    print(params)\n",
    "    km = KnnModel(\n",
    "        metric=params['metric'], \n",
    "        metric_label=params['metric_label'],\n",
    "        k=params['k'],\n",
    "        equalWeights=params['equal'],\n",
    "        includeCategorical=params['categorical'],\n",
    "        p=params['p']\n",
    "    )\n",
    "    return km\n",
    "    \n",
    "rows = []\n",
    "M = 5\n",
    "for model_i in range(M):\n",
    "    # Worst M models\n",
    "    row = dfModels.iloc[:M].iloc[model_i]\n",
    "    km = modelFromDfRow(row)\n",
    "    print('Score = ' + str(km.score))\n",
    "    rowDict = km.rowDict\n",
    "    rowDict['rank'] = -M + model_i\n",
    "    rows.append(rowDict)\n",
    "for model_i in range(M):\n",
    "    # Best M models\n",
    "    row = dfModels.iloc[-M:].iloc[model_i]\n",
    "    km = modelFromDfRow(row)\n",
    "    print('Score = ' + str(km.score))\n",
    "    rowDict = km.rowDict\n",
    "    rowDict['rank'] = 1 + model_i\n",
    "    rows.append(rowDict)\n",
    "    \n",
    "dfBestWorst  = pd.DataFrame(columns=['metric', 'categorical', 'equal', 'k', 'score', 'rank'])\n",
    "for i, row in enumerate(rows):\n",
    "    dfBestWorst.loc[i] = row\n",
    "dfBestWorst.to_csv('knn_best_worst_scores.csv')\n",
    "\n",
    "print(dfBestWorst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, it looks like the best model uses the Minkowski metric of order 4 with equal weighting and includes the categorical 'home_ownership' variable. Now we just need to find the best value of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 10, score: 0.8638\n",
      "k: 11, score: 0.8632\n",
      "k: 12, score: 0.8639333333333333\n",
      "k: 13, score: 0.8638666666666667\n",
      "k: 14, score: 0.8637333333333334\n",
      "k: 15, score: 0.8638\n",
      "k: 16, score: 0.8636666666666667\n",
      "k: 17, score: 0.8637333333333334\n",
      "k: 18, score: 0.8636\n",
      "k: 19, score: 0.8636\n"
     ]
    }
   ],
   "source": [
    "for k in range(10, 20):\n",
    "    km = KnnModel(\n",
    "        metric='minkowski',\n",
    "        p=4,\n",
    "        metric_label='minkowski (p=4)',\n",
    "        k=k,\n",
    "        equalWeights=True,\n",
    "        includeCategorical=True\n",
    "    )\n",
    "    print('k: ' + str(k) + ', score: ' + str(km.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance peaks at k=12.\n",
    "\n",
    "The final k-nearest neighbors model uses the Minkowski order-4 metric with equal weighting and k=12, and its accuracy on the full test data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of final KNN model: 0.8646614168257926\n"
     ]
    }
   ],
   "source": [
    "X_train_full = train[X_cols_full]\n",
    "X_test_full = test[X_cols_full]\n",
    "scaler_full = MinMaxScaler()\n",
    "X_train_full = scaler_full.fit_transform(X_train_full)\n",
    "X_test_full = scaler_full.transform(X_test_full)\n",
    "\n",
    "X_train_minusCat = train[X_cols_minusCat]\n",
    "X_test_minusCat = test[X_cols_minusCat]\n",
    "scaler_minusCat = MinMaxScaler()\n",
    "X_train_minusCat = scaler_minusCat.fit_transform(X_train_minusCat)\n",
    "X_test_minusCat = scaler_minusCat.transform(X_test_minusCat)\n",
    "\n",
    "y_train, y_test = train.Default, test.Default\n",
    "\n",
    "km = KnnModel(\n",
    "    metric='minkowski', \n",
    "    metric_label='minkowski (p=4)',\n",
    "    k=12,\n",
    "    equalWeights=True,\n",
    "    includeCategorical=True\n",
    ")\n",
    "print('Accuracy of final KNN model: ' + str(km.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model\n",
    "\n",
    "For our logistic regression model we consider two parameters: L1 versus L2 regularization, and the strength of regularization. We use the same approach of testing different values within the parameter range and rank them by their score on the sample test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: l1, 0.005\n",
      "Computing: l1, 0.01\n",
      "Computing: l1, 0.015\n",
      "Computing: l1, 0.02\n",
      "Computing: l1, 0.04\n",
      "Computing: l1, 0.07\n",
      "Computing: l1, 0.1\n",
      "Computing: l1, 0.2\n",
      "Computing: l1, 0.4\n",
      "Computing: l1, 0.7\n",
      "Computing: l1, 1\n",
      "Computing: l2, 0.005\n",
      "Computing: l2, 0.01\n",
      "Computing: l2, 0.015\n",
      "Computing: l2, 0.02\n",
      "Computing: l2, 0.04\n",
      "Computing: l2, 0.07\n",
      "Computing: l2, 0.1\n",
      "Computing: l2, 0.2\n",
      "Computing: l2, 0.4\n",
      "Computing: l2, 0.7\n",
      "Computing: l2, 1\n",
      "[['l1', 0.7, 0.8650322723183992],\n",
      " ['l2', 0.7, 0.8650322723183992],\n",
      " ['l1', 1, 0.8650401628607951],\n",
      " ['l2', 1, 0.8650480534031909],\n",
      " ['l2', 0.4, 0.8650559439455868],\n",
      " ['l1', 0.4, 0.8650638344879827],\n",
      " ['l2', 0.2, 0.8650796155727745],\n",
      " ['l1', 0.2, 0.8650875061151704],\n",
      " ['l1', 0.1, 0.8650953966575663],\n",
      " ['l1', 0.07, 0.8651032871999621],\n",
      " ['l2', 0.1, 0.8651032871999621],\n",
      " ['l1', 0.04, 0.865111177742358],\n",
      " ['l1', 0.005, 0.8651190682847539],\n",
      " ['l1', 0.01, 0.8651190682847539],\n",
      " ['l2', 0.005, 0.8651190682847539],\n",
      " ['l2', 0.01, 0.8651190682847539],\n",
      " ['l2', 0.04, 0.8651190682847539],\n",
      " ['l2', 0.07, 0.8651190682847539],\n",
      " ['l1', 0.015, 0.8651269588271497],\n",
      " ['l1', 0.02, 0.8651269588271497],\n",
      " ['l2', 0.015, 0.8651269588271497],\n",
      " ['l2', 0.02, 0.8651269588271497]]\n"
     ]
    }
   ],
   "source": [
    "X_cols = [c for c in train.columns if not c in ('Default', 'issue_d')]\n",
    "X_train = train[X_cols]\n",
    "X_test = test[X_cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train, y_test = train.Default, test.Default\n",
    "\n",
    "regs = ['l1', 'l2']\n",
    "Cs = [0.005, 0.01, 0.015, 0.02, 0.04, 0.07, 0.1, 0.2, 0.4, 0.7, 1]\n",
    "\n",
    "scores = []\n",
    "for reg in regs:\n",
    "    for C in Cs:\n",
    "        print('Computing: ' + reg + ', '+ str(C))\n",
    "        model = LogisticRegression(penalty=reg, C=C).fit(X_train, y_train)\n",
    "        scores.append([reg, C, model.score(X_test, y_test)])\n",
    "scores = sorted(scores, key=lambda x: x[2])\n",
    "print(pprint.pformat(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the best models are two L1 models with C parameters of .015 and .02 (note: smaller C means more regularization). L1 regularization causes many of the coefficients to be set to 0, performing de facto feature selection. Let's see which features these models selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 model, C=0.015\n",
      "[('home_ownership', -0.5952603981947261),\n",
      " ('acc_open_past_24mths', 1.5062144613709292),\n",
      " ('dti', 0.7050401115210349),\n",
      " ('inq_last_6mths', 0.25749025235936035),\n",
      " ('mo_sin_old_il_acct', -0.06004876133166225),\n",
      " ('mo_sin_old_rev_tl_op', -0.6473424652380454),\n",
      " ('mo_sin_rcnt_rev_tl_op', -0.012564525137396348),\n",
      " ('mths_since_recent_inq', -0.4666571562074985),\n",
      " ('num_il_tl', -0.518020756977413),\n",
      " ('num_tl_op_past_12m', 0.2654490310199626),\n",
      " ('pct_tl_nvr_dlq', -0.3661138397111568),\n",
      " ('percent_bc_gt_75', 0.45736388854062354),\n",
      " ('total_acc', -0.2717059913656659)]\n",
      "----\n",
      "L1 model, C=0.02\n",
      "[('home_ownership', -0.5866106404340918),\n",
      " ('acc_open_past_24mths', 1.6050420403617753),\n",
      " ('dti', 0.7498210116131567),\n",
      " ('inq_last_6mths', 0.35396742895733146),\n",
      " ('mo_sin_old_il_acct', -0.07408169743568527),\n",
      " ('mo_sin_old_rev_tl_op', -0.6979957453146806),\n",
      " ('mo_sin_rcnt_rev_tl_op', -0.19318363040245998),\n",
      " ('mths_since_recent_inq', -0.42197501842372487),\n",
      " ('num_il_tl', -0.5548406870316974),\n",
      " ('num_rev_tl_bal_gt_0', 0.1823820536737626),\n",
      " ('num_tl_op_past_12m', 0.5911500885770686),\n",
      " ('pct_tl_nvr_dlq', -0.45801770787627477),\n",
      " ('percent_bc_gt_75', 0.4833831271844299),\n",
      " ('total_acc', -0.4963629505565848)]\n"
     ]
    }
   ],
   "source": [
    "print('L1 model, C=0.015')\n",
    "model = LogisticRegression(penalty='l1', C=0.015).fit(X_train, y_train)\n",
    "selected_features = list(zip(X_cols, model.coef_.ravel()))\n",
    "selected_features = [f for f in selected_features if f[1] != 0]\n",
    "print(pprint.pformat(selected_features))\n",
    "\n",
    "print('----')\n",
    "\n",
    "print('L1 model, C=0.02')\n",
    "model = LogisticRegression(penalty='l1', C=0.02).fit(X_train, y_train)\n",
    "selected_features = list(zip(X_cols, model.coef_.ravel()))\n",
    "selected_features = [f for f in selected_features if f[1] != 0]\n",
    "print(pprint.pformat(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are almost the same, except for the variable 'num_rev_tl_bal_gt_0' (number of revolving trades with balance greater than zero). Both models have the same accuracy on the test set so for sake of parsimony we use the C=0.015 model with one fewer variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of final Logistic Regression model: 0.8651269588271497\n"
     ]
    }
   ],
   "source": [
    "logModel = LogisticRegression(penalty='l1', C=0.015).fit(X_train, y_train)\n",
    "print('Accuracy of final Logistic Regression model: ' + str(logModel.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that the logistic regression model offers slightly better performance than the k-nearest neighbors model (86.51% compared to 86.49%) while being much faster to use, performing feature selection, and yielding insight into the importance of each variable in the prediction.\n",
    "\n",
    "### Gradient boosting model\n",
    "\n",
    "Now we'll try a gradient boosting model using a sequence of small decision trees. The parameters to be adjusted are the loss function, the learning rate (which weights contributions from each tree), the maximum tree depth, and the number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train.sample(n=10000, replace=False)\n",
    "test_sample = test.sample(n=10000, replace=False)\n",
    "\n",
    "X_train, X_test = train_sample[X_cols], test_sample[X_cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train, y_test = train_sample.Default, test_sample.Default\n",
    "\n",
    "class GBModel:\n",
    "    def __init__(self, lossOption, learningRate, treeDepth, treeNum):\n",
    "        \"\"\"Compute gradient boosting model, score, and dict for row in dataframe\"\"\"\n",
    "        self.model = GradientBoostingClassifier(\n",
    "            loss=lossOption,\n",
    "            learning_rate=learningRate,\n",
    "            n_estimators=treeNum,\n",
    "            subsample=0.5,\n",
    "            max_depth=treeDepth\n",
    "        ).fit(X_train, y_train)\n",
    "        self.score = self.model.score(X_test, y_test)\n",
    "        self.rowDict = {\n",
    "            'loss': lossOption,\n",
    "            'learn_rate': learningRate,\n",
    "            'tree_depth': treeDepth,\n",
    "            'tree_num': treeNum,\n",
    "            'score': self.score\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing parameters: deviance, 1, 2, 80\n",
      "Score = 0.8342\n",
      "Computing parameters: deviance, 1, 2, 90\n",
      "Score = 0.8196666666666667\n",
      "Computing parameters: deviance, 1, 2, 100\n",
      "Score = 0.8235333333333333\n",
      "Computing parameters: deviance, 1, 2, 110\n",
      "Score = 0.8384666666666667\n",
      "Computing parameters: deviance, 1, 2, 120\n",
      "Score = 0.8076\n",
      "Computing parameters: deviance, 1, 3, 80\n",
      "Score = 0.7777333333333334\n",
      "Computing parameters: deviance, 1, 3, 90\n",
      "Score = 0.7885333333333333\n",
      "Computing parameters: deviance, 1, 3, 100\n",
      "Score = 0.7811333333333333\n",
      "Computing parameters: deviance, 1, 3, 110\n",
      "Score = 0.7972666666666667\n",
      "Computing parameters: deviance, 1, 3, 120\n",
      "Score = 0.7794666666666666\n",
      "Computing parameters: deviance, 1, 4, 80\n",
      "Score = 0.7592\n",
      "Computing parameters: deviance, 1, 4, 90\n",
      "Score = 0.7744\n",
      "Computing parameters: deviance, 1, 4, 100\n",
      "Score = 0.7644\n",
      "Computing parameters: deviance, 1, 4, 110\n",
      "Score = 0.7842\n",
      "Computing parameters: deviance, 1, 4, 120\n",
      "Score = 0.7703333333333333\n",
      "Computing parameters: deviance, 1, 5, 80\n",
      "Score = 0.7652666666666667\n",
      "Computing parameters: deviance, 1, 5, 90\n",
      "Score = 0.7411333333333333\n",
      "Computing parameters: deviance, 1, 5, 100\n",
      "Score = 0.7777333333333334\n",
      "Computing parameters: deviance, 1, 5, 110\n",
      "Score = 0.7583333333333333\n",
      "Computing parameters: deviance, 1, 5, 120\n",
      "Score = 0.7664\n",
      "Computing parameters: deviance, 0.5, 2, 80\n",
      "Score = 0.8384666666666667\n",
      "Computing parameters: deviance, 0.5, 2, 90\n",
      "Score = 0.8360666666666666\n",
      "Computing parameters: deviance, 0.5, 2, 100\n",
      "Score = 0.8315333333333333\n",
      "Computing parameters: deviance, 0.5, 2, 110\n",
      "Score = 0.8232\n",
      "Computing parameters: deviance, 0.5, 2, 120\n",
      "Score = 0.8339333333333333\n",
      "Computing parameters: deviance, 0.5, 3, 80\n",
      "Score = 0.8170666666666667\n",
      "Computing parameters: deviance, 0.5, 3, 90\n",
      "Score = 0.8173333333333334\n",
      "Computing parameters: deviance, 0.5, 3, 100\n",
      "Score = 0.8089333333333333\n",
      "Computing parameters: deviance, 0.5, 3, 110\n",
      "Score = 0.8112666666666667\n",
      "Computing parameters: deviance, 0.5, 3, 120\n",
      "Score = 0.8119333333333333\n",
      "Computing parameters: deviance, 0.5, 4, 80\n",
      "Score = 0.8096\n",
      "Computing parameters: deviance, 0.5, 4, 90\n",
      "Score = 0.7967333333333333\n",
      "Computing parameters: deviance, 0.5, 4, 100\n",
      "Score = 0.7996\n",
      "Computing parameters: deviance, 0.5, 4, 110\n",
      "Score = 0.7983333333333333\n",
      "Computing parameters: deviance, 0.5, 4, 120\n",
      "Score = 0.7954\n",
      "Computing parameters: deviance, 0.5, 5, 80\n",
      "Score = 0.7952\n",
      "Computing parameters: deviance, 0.5, 5, 90\n",
      "Score = 0.7900666666666667\n",
      "Computing parameters: deviance, 0.5, 5, 100\n",
      "Score = 0.7841333333333333\n",
      "Computing parameters: deviance, 0.5, 5, 110\n",
      "Score = 0.7895333333333333\n",
      "Computing parameters: deviance, 0.5, 5, 120\n",
      "Score = 0.7812666666666667\n",
      "Computing parameters: deviance, 0.3, 2, 80\n",
      "Score = 0.8467333333333333\n",
      "Computing parameters: deviance, 0.3, 2, 90\n",
      "Score = 0.8462666666666666\n",
      "Computing parameters: deviance, 0.3, 2, 100\n",
      "Score = 0.8460666666666666\n",
      "Computing parameters: deviance, 0.3, 2, 110\n",
      "Score = 0.8418\n",
      "Computing parameters: deviance, 0.3, 2, 120\n",
      "Score = 0.8416666666666667\n",
      "Computing parameters: deviance, 0.3, 3, 80\n",
      "Score = 0.826\n",
      "Computing parameters: deviance, 0.3, 3, 90\n",
      "Score = 0.8227333333333333\n",
      "Computing parameters: deviance, 0.3, 3, 100\n",
      "Score = 0.8281333333333334\n",
      "Computing parameters: deviance, 0.3, 3, 110\n",
      "Score = 0.8297333333333333\n",
      "Computing parameters: deviance, 0.3, 3, 120\n",
      "Score = 0.8261333333333334\n",
      "Computing parameters: deviance, 0.3, 4, 80\n",
      "Score = 0.8226666666666667\n",
      "Computing parameters: deviance, 0.3, 4, 90\n",
      "Score = 0.8196666666666667\n",
      "Computing parameters: deviance, 0.3, 4, 100\n",
      "Score = 0.8122666666666667\n",
      "Computing parameters: deviance, 0.3, 4, 110\n",
      "Score = 0.8151333333333334\n",
      "Computing parameters: deviance, 0.3, 4, 120\n",
      "Score = 0.8209333333333333\n",
      "Computing parameters: deviance, 0.3, 5, 80\n",
      "Score = 0.8048666666666666\n",
      "Computing parameters: deviance, 0.3, 5, 90\n",
      "Score = 0.8097333333333333\n",
      "Computing parameters: deviance, 0.3, 5, 100\n",
      "Score = 0.8119333333333333\n",
      "Computing parameters: deviance, 0.3, 5, 110\n",
      "Score = 0.8120666666666667\n",
      "Computing parameters: deviance, 0.3, 5, 120\n",
      "Score = 0.805\n",
      "Computing parameters: deviance, 0.2, 2, 80\n",
      "Score = 0.8494\n",
      "Computing parameters: deviance, 0.2, 2, 90\n",
      "Score = 0.8508666666666667\n",
      "Computing parameters: deviance, 0.2, 2, 100\n",
      "Score = 0.8519333333333333\n",
      "Computing parameters: deviance, 0.2, 2, 110\n",
      "Score = 0.8512666666666666\n",
      "Computing parameters: deviance, 0.2, 2, 120\n",
      "Score = 0.8491333333333333\n",
      "Computing parameters: deviance, 0.2, 3, 80\n",
      "Score = 0.8471333333333333\n",
      "Computing parameters: deviance, 0.2, 3, 90\n",
      "Score = 0.8404666666666667\n",
      "Computing parameters: deviance, 0.2, 3, 100\n",
      "Score = 0.8448666666666667\n",
      "Computing parameters: deviance, 0.2, 3, 110\n",
      "Score = 0.8334\n",
      "Computing parameters: deviance, 0.2, 3, 120\n",
      "Score = 0.8390666666666666\n",
      "Computing parameters: deviance, 0.2, 4, 80\n",
      "Score = 0.8358666666666666\n",
      "Computing parameters: deviance, 0.2, 4, 90\n",
      "Score = 0.8324666666666667\n",
      "Computing parameters: deviance, 0.2, 4, 100\n",
      "Score = 0.8337333333333333\n",
      "Computing parameters: deviance, 0.2, 4, 110\n",
      "Score = 0.8366\n",
      "Computing parameters: deviance, 0.2, 4, 120\n",
      "Score = 0.8294\n",
      "Computing parameters: deviance, 0.2, 5, 80\n",
      "Score = 0.8300666666666666\n",
      "Computing parameters: deviance, 0.2, 5, 90\n",
      "Score = 0.8302\n",
      "Computing parameters: deviance, 0.2, 5, 100\n",
      "Score = 0.8291333333333334\n",
      "Computing parameters: deviance, 0.2, 5, 110\n",
      "Score = 0.8292666666666667\n",
      "Computing parameters: deviance, 0.2, 5, 120\n",
      "Score = 0.8276666666666667\n",
      "Computing parameters: deviance, 0.1, 2, 80\n",
      "Score = 0.862\n",
      "Computing parameters: deviance, 0.1, 2, 90\n",
      "Score = 0.8599333333333333\n",
      "Computing parameters: deviance, 0.1, 2, 100\n",
      "Score = 0.8607333333333334\n",
      "Computing parameters: deviance, 0.1, 2, 110\n",
      "Score = 0.8597333333333333\n",
      "Computing parameters: deviance, 0.1, 2, 120\n",
      "Score = 0.8594\n",
      "Computing parameters: deviance, 0.1, 3, 80\n",
      "Score = 0.8577333333333333\n",
      "Computing parameters: deviance, 0.1, 3, 90\n",
      "Score = 0.8564\n",
      "Computing parameters: deviance, 0.1, 3, 100\n",
      "Score = 0.8583333333333333\n",
      "Computing parameters: deviance, 0.1, 3, 110\n",
      "Score = 0.8566666666666667\n",
      "Computing parameters: deviance, 0.1, 3, 120\n",
      "Score = 0.8549333333333333\n",
      "Computing parameters: deviance, 0.1, 4, 80\n",
      "Score = 0.8542\n",
      "Computing parameters: deviance, 0.1, 4, 90\n",
      "Score = 0.8544\n",
      "Computing parameters: deviance, 0.1, 4, 100\n",
      "Score = 0.8522666666666666\n",
      "Computing parameters: deviance, 0.1, 4, 110\n",
      "Score = 0.8497333333333333\n",
      "Computing parameters: deviance, 0.1, 4, 120\n",
      "Score = 0.8491333333333333\n",
      "Computing parameters: deviance, 0.1, 5, 80\n",
      "Score = 0.8485333333333334\n",
      "Computing parameters: deviance, 0.1, 5, 90\n",
      "Score = 0.8499333333333333\n",
      "Computing parameters: deviance, 0.1, 5, 100\n",
      "Score = 0.8512666666666666\n",
      "Computing parameters: deviance, 0.1, 5, 110\n",
      "Score = 0.8481333333333333\n",
      "Computing parameters: deviance, 0.1, 5, 120\n",
      "Score = 0.8492\n",
      "Computing parameters: deviance, 0.05, 2, 80\n",
      "Score = 0.8637333333333334\n",
      "Computing parameters: deviance, 0.05, 2, 90\n",
      "Score = 0.8632\n",
      "Computing parameters: deviance, 0.05, 2, 100\n",
      "Score = 0.8632666666666666\n",
      "Computing parameters: deviance, 0.05, 2, 110\n",
      "Score = 0.8634\n",
      "Computing parameters: deviance, 0.05, 2, 120\n",
      "Score = 0.8628\n",
      "Computing parameters: deviance, 0.05, 3, 80\n",
      "Score = 0.8630666666666666\n",
      "Computing parameters: deviance, 0.05, 3, 90\n",
      "Score = 0.8622\n",
      "Computing parameters: deviance, 0.05, 3, 100\n",
      "Score = 0.8615333333333334\n",
      "Computing parameters: deviance, 0.05, 3, 110\n",
      "Score = 0.8622666666666666\n",
      "Computing parameters: deviance, 0.05, 3, 120\n",
      "Score = 0.8615333333333334\n",
      "Computing parameters: deviance, 0.05, 4, 80\n",
      "Score = 0.8616\n",
      "Computing parameters: deviance, 0.05, 4, 90\n",
      "Score = 0.8598\n",
      "Computing parameters: deviance, 0.05, 4, 100\n",
      "Score = 0.8598\n",
      "Computing parameters: deviance, 0.05, 4, 110\n",
      "Score = 0.8608\n",
      "Computing parameters: deviance, 0.05, 4, 120\n",
      "Score = 0.8595333333333334\n",
      "Computing parameters: deviance, 0.05, 5, 80\n",
      "Score = 0.8594\n",
      "Computing parameters: deviance, 0.05, 5, 90\n",
      "Score = 0.8588\n",
      "Computing parameters: deviance, 0.05, 5, 100\n",
      "Score = 0.8595333333333334\n",
      "Computing parameters: deviance, 0.05, 5, 110\n",
      "Score = 0.858\n",
      "Computing parameters: deviance, 0.05, 5, 120\n",
      "Score = 0.8578666666666667\n",
      "Computing parameters: exponential, 1, 2, 80\n",
      "Score = 0.8230666666666666\n",
      "Computing parameters: exponential, 1, 2, 90\n",
      "Score = 0.8052666666666667\n",
      "Computing parameters: exponential, 1, 2, 100\n",
      "Score = 0.8163333333333334\n",
      "Computing parameters: exponential, 1, 2, 110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.8162666666666667\n",
      "Computing parameters: exponential, 1, 2, 120\n",
      "Score = 0.806\n",
      "Computing parameters: exponential, 1, 3, 80\n",
      "Score = 0.8101333333333334\n",
      "Computing parameters: exponential, 1, 3, 90\n",
      "Score = 0.8070666666666667\n",
      "Computing parameters: exponential, 1, 3, 100\n",
      "Score = 0.8040666666666667\n",
      "Computing parameters: exponential, 1, 3, 110\n",
      "Score = 0.7984\n",
      "Computing parameters: exponential, 1, 3, 120\n",
      "Score = 0.7938666666666667\n",
      "Computing parameters: exponential, 1, 4, 80\n",
      "Score = 0.8078\n",
      "Computing parameters: exponential, 1, 4, 90\n",
      "Score = 0.8\n",
      "Computing parameters: exponential, 1, 4, 100\n",
      "Score = 0.8015333333333333\n",
      "Computing parameters: exponential, 1, 4, 110\n",
      "Score = 0.7987333333333333\n",
      "Computing parameters: exponential, 1, 4, 120\n",
      "Score = 0.8024\n",
      "Computing parameters: exponential, 1, 5, 80\n",
      "Score = 0.8096\n",
      "Computing parameters: exponential, 1, 5, 90\n",
      "Score = 0.8006\n",
      "Computing parameters: exponential, 1, 5, 100\n",
      "Score = 0.8101333333333334\n",
      "Computing parameters: exponential, 1, 5, 110\n",
      "Score = 0.8037333333333333\n",
      "Computing parameters: exponential, 1, 5, 120\n",
      "Score = 0.8165333333333333\n",
      "Computing parameters: exponential, 0.5, 2, 80\n",
      "Score = 0.8499333333333333\n",
      "Computing parameters: exponential, 0.5, 2, 90\n",
      "Score = 0.8482666666666666\n",
      "Computing parameters: exponential, 0.5, 2, 100\n",
      "Score = 0.845\n",
      "Computing parameters: exponential, 0.5, 2, 110\n",
      "Score = 0.8426\n",
      "Computing parameters: exponential, 0.5, 2, 120\n",
      "Score = 0.8403333333333334\n",
      "Computing parameters: exponential, 0.5, 3, 80\n",
      "Score = 0.8399333333333333\n",
      "Computing parameters: exponential, 0.5, 3, 90\n",
      "Score = 0.8368666666666666\n",
      "Computing parameters: exponential, 0.5, 3, 100\n",
      "Score = 0.8382\n",
      "Computing parameters: exponential, 0.5, 3, 110\n",
      "Score = 0.8348\n",
      "Computing parameters: exponential, 0.5, 3, 120\n",
      "Score = 0.8383333333333334\n",
      "Computing parameters: exponential, 0.5, 4, 80\n",
      "Score = 0.8352\n",
      "Computing parameters: exponential, 0.5, 4, 90\n",
      "Score = 0.8295333333333333\n",
      "Computing parameters: exponential, 0.5, 4, 100\n",
      "Score = 0.829\n",
      "Computing parameters: exponential, 0.5, 4, 110\n",
      "Score = 0.825\n",
      "Computing parameters: exponential, 0.5, 4, 120\n",
      "Score = 0.8324666666666667\n",
      "Computing parameters: exponential, 0.5, 5, 80\n",
      "Score = 0.8298\n",
      "Computing parameters: exponential, 0.5, 5, 90\n",
      "Score = 0.8353333333333334\n",
      "Computing parameters: exponential, 0.5, 5, 100\n",
      "Score = 0.8312\n",
      "Computing parameters: exponential, 0.5, 5, 110\n",
      "Score = 0.8306\n",
      "Computing parameters: exponential, 0.5, 5, 120\n",
      "Score = 0.8313333333333334\n",
      "Computing parameters: exponential, 0.3, 2, 80\n",
      "Score = 0.8579333333333333\n",
      "Computing parameters: exponential, 0.3, 2, 90\n",
      "Score = 0.8570666666666666\n",
      "Computing parameters: exponential, 0.3, 2, 100\n",
      "Score = 0.8562\n",
      "Computing parameters: exponential, 0.3, 2, 110\n",
      "Score = 0.8554666666666667\n",
      "Computing parameters: exponential, 0.3, 2, 120\n",
      "Score = 0.8574\n",
      "Computing parameters: exponential, 0.3, 3, 80\n",
      "Score = 0.8545333333333334\n",
      "Computing parameters: exponential, 0.3, 3, 90\n",
      "Score = 0.8538\n",
      "Computing parameters: exponential, 0.3, 3, 100\n",
      "Score = 0.8533333333333334\n",
      "Computing parameters: exponential, 0.3, 3, 110\n",
      "Score = 0.8518666666666667\n",
      "Computing parameters: exponential, 0.3, 3, 120\n",
      "Score = 0.8516\n",
      "Computing parameters: exponential, 0.3, 4, 80\n",
      "Score = 0.8498666666666667\n",
      "Computing parameters: exponential, 0.3, 4, 90\n",
      "Score = 0.8489333333333333\n",
      "Computing parameters: exponential, 0.3, 4, 100\n",
      "Score = 0.8498666666666667\n",
      "Computing parameters: exponential, 0.3, 4, 110\n",
      "Score = 0.8483333333333334\n",
      "Computing parameters: exponential, 0.3, 4, 120\n",
      "Score = 0.8457333333333333\n",
      "Computing parameters: exponential, 0.3, 5, 80\n",
      "Score = 0.8500666666666666\n",
      "Computing parameters: exponential, 0.3, 5, 90\n",
      "Score = 0.8484666666666667\n",
      "Computing parameters: exponential, 0.3, 5, 100\n",
      "Score = 0.8437333333333333\n",
      "Computing parameters: exponential, 0.3, 5, 110\n",
      "Score = 0.846\n",
      "Computing parameters: exponential, 0.3, 5, 120\n",
      "Score = 0.8463333333333334\n",
      "Computing parameters: exponential, 0.2, 2, 80\n",
      "Score = 0.8623333333333333\n",
      "Computing parameters: exponential, 0.2, 2, 90\n",
      "Score = 0.8616666666666667\n",
      "Computing parameters: exponential, 0.2, 2, 100\n",
      "Score = 0.861\n",
      "Computing parameters: exponential, 0.2, 2, 110\n",
      "Score = 0.8616\n",
      "Computing parameters: exponential, 0.2, 2, 120\n",
      "Score = 0.8574666666666667\n",
      "Computing parameters: exponential, 0.2, 3, 80\n",
      "Score = 0.8590666666666666\n",
      "Computing parameters: exponential, 0.2, 3, 90\n",
      "Score = 0.858\n",
      "Computing parameters: exponential, 0.2, 3, 100\n",
      "Score = 0.8592666666666666\n",
      "Computing parameters: exponential, 0.2, 3, 110\n",
      "Score = 0.8586666666666667\n",
      "Computing parameters: exponential, 0.2, 3, 120\n",
      "Score = 0.8568666666666667\n",
      "Computing parameters: exponential, 0.2, 4, 80\n",
      "Score = 0.8576\n",
      "Computing parameters: exponential, 0.2, 4, 90\n",
      "Score = 0.8558666666666667\n",
      "Computing parameters: exponential, 0.2, 4, 100\n",
      "Score = 0.8583333333333333\n",
      "Computing parameters: exponential, 0.2, 4, 110\n",
      "Score = 0.8550666666666666\n",
      "Computing parameters: exponential, 0.2, 4, 120\n",
      "Score = 0.8555333333333334\n",
      "Computing parameters: exponential, 0.2, 5, 80\n",
      "Score = 0.8568\n",
      "Computing parameters: exponential, 0.2, 5, 90\n",
      "Score = 0.8552666666666666\n",
      "Computing parameters: exponential, 0.2, 5, 100\n",
      "Score = 0.852\n",
      "Computing parameters: exponential, 0.2, 5, 110\n",
      "Score = 0.8529333333333333\n",
      "Computing parameters: exponential, 0.2, 5, 120\n",
      "Score = 0.8536\n",
      "Computing parameters: exponential, 0.1, 2, 80\n",
      "Score = 0.8636666666666667\n",
      "Computing parameters: exponential, 0.1, 2, 90\n",
      "Score = 0.864\n",
      "Computing parameters: exponential, 0.1, 2, 100\n",
      "Score = 0.8635333333333334\n",
      "Computing parameters: exponential, 0.1, 2, 110\n",
      "Score = 0.8638\n",
      "Computing parameters: exponential, 0.1, 2, 120\n",
      "Score = 0.8634666666666667\n",
      "Computing parameters: exponential, 0.1, 3, 80\n",
      "Score = 0.8628\n",
      "Computing parameters: exponential, 0.1, 3, 90\n",
      "Score = 0.8630666666666666\n",
      "Computing parameters: exponential, 0.1, 3, 100\n",
      "Score = 0.8628666666666667\n",
      "Computing parameters: exponential, 0.1, 3, 110\n",
      "Score = 0.863\n",
      "Computing parameters: exponential, 0.1, 3, 120\n",
      "Score = 0.8624\n",
      "Computing parameters: exponential, 0.1, 4, 80\n",
      "Score = 0.8626666666666667\n",
      "Computing parameters: exponential, 0.1, 4, 90\n",
      "Score = 0.8623333333333333\n",
      "Computing parameters: exponential, 0.1, 4, 100\n",
      "Score = 0.8622666666666666\n",
      "Computing parameters: exponential, 0.1, 4, 110\n",
      "Score = 0.8622666666666666\n",
      "Computing parameters: exponential, 0.1, 4, 120\n",
      "Score = 0.8614\n",
      "Computing parameters: exponential, 0.1, 5, 80\n",
      "Score = 0.8623333333333333\n",
      "Computing parameters: exponential, 0.1, 5, 90\n",
      "Score = 0.8626\n",
      "Computing parameters: exponential, 0.1, 5, 100\n",
      "Score = 0.8616\n",
      "Computing parameters: exponential, 0.1, 5, 110\n",
      "Score = 0.8606\n",
      "Computing parameters: exponential, 0.1, 5, 120\n",
      "Score = 0.8604666666666667\n",
      "Computing parameters: exponential, 0.05, 2, 80\n",
      "Score = 0.8636666666666667\n",
      "Computing parameters: exponential, 0.05, 2, 90\n",
      "Score = 0.8636666666666667\n",
      "Computing parameters: exponential, 0.05, 2, 100\n",
      "Score = 0.8636666666666667\n",
      "Computing parameters: exponential, 0.05, 2, 110\n",
      "Score = 0.8637333333333334\n",
      "Computing parameters: exponential, 0.05, 2, 120\n",
      "Score = 0.8636\n",
      "Computing parameters: exponential, 0.05, 3, 80\n",
      "Score = 0.8636666666666667\n",
      "Computing parameters: exponential, 0.05, 3, 90\n",
      "Score = 0.8636666666666667\n",
      "Computing parameters: exponential, 0.05, 3, 100\n",
      "Score = 0.8638\n",
      "Computing parameters: exponential, 0.05, 3, 110\n",
      "Score = 0.8634666666666667\n",
      "Computing parameters: exponential, 0.05, 3, 120\n",
      "Score = 0.8634666666666667\n",
      "Computing parameters: exponential, 0.05, 4, 80\n",
      "Score = 0.8636666666666667\n",
      "Computing parameters: exponential, 0.05, 4, 90\n",
      "Score = 0.8636\n",
      "Computing parameters: exponential, 0.05, 4, 100\n",
      "Score = 0.8637333333333334\n",
      "Computing parameters: exponential, 0.05, 4, 110\n",
      "Score = 0.8637333333333334\n",
      "Computing parameters: exponential, 0.05, 4, 120\n",
      "Score = 0.8635333333333334\n",
      "Computing parameters: exponential, 0.05, 5, 80\n",
      "Score = 0.8636666666666667\n",
      "Computing parameters: exponential, 0.05, 5, 90\n",
      "Score = 0.8632666666666666\n",
      "Computing parameters: exponential, 0.05, 5, 100\n",
      "Score = 0.8636\n",
      "Computing parameters: exponential, 0.05, 5, 110\n",
      "Score = 0.8635333333333334\n",
      "Computing parameters: exponential, 0.05, 5, 120\n",
      "Score = 0.8636\n"
     ]
    }
   ],
   "source": [
    "lossOptions = ['deviance', 'exponential']\n",
    "learningRates = [1, 0.5, 0.3, 0.2, 0.1, 0.05]\n",
    "treeDepths = [2, 3, 4, 5]\n",
    "treeNums = [80, 90, 100, 110, 120]\n",
    "\n",
    "rows = []\n",
    "for lossOption in lossOptions:\n",
    "    for learningRate in learningRates:\n",
    "        for treeDepth in treeDepths:\n",
    "            for treeNum in treeNums:\n",
    "                print(\n",
    "                    'Computing parameters: ' + \\\n",
    "                    ', '.join( [lossOption, str(learningRate), str(treeDepth), str(treeNum)] )\n",
    "                )\n",
    "                gbm = GBModel(lossOption, learningRate, treeDepth, treeNum)\n",
    "                print('Score = ' + str(gbm.score))\n",
    "                rows.append(gbm.rowDict)\n",
    "\n",
    "dfModels  = pd.DataFrame(columns=['loss', 'learn_rate', 'tree_depth', 'tree_num', 'score'])\n",
    "for i, row in enumerate(rows):\n",
    "    dfModels.loc[i] = row\n",
    "dfModels.to_csv('gbm_test_model_scores.csv')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            loss  learn_rate  tree_depth  tree_num     score\n",
      "16      deviance        1.00           5        90  0.741133\n",
      "18      deviance        1.00           5       110  0.758333\n",
      "10      deviance        1.00           4        80  0.759200\n",
      "12      deviance        1.00           4       100  0.764400\n",
      "15      deviance        1.00           5        80  0.765267\n",
      "19      deviance        1.00           5       120  0.766400\n",
      "14      deviance        1.00           4       120  0.770333\n",
      "11      deviance        1.00           4        90  0.774400\n",
      "5       deviance        1.00           3        80  0.777733\n",
      "17      deviance        1.00           5       100  0.777733\n",
      "9       deviance        1.00           3       120  0.779467\n",
      "7       deviance        1.00           3       100  0.781133\n",
      "39      deviance        0.50           5       120  0.781267\n",
      "37      deviance        0.50           5       100  0.784133\n",
      "13      deviance        1.00           4       110  0.784200\n",
      "6       deviance        1.00           3        90  0.788533\n",
      "38      deviance        0.50           5       110  0.789533\n",
      "36      deviance        0.50           5        90  0.790067\n",
      "129  exponential        1.00           3       120  0.793867\n",
      "35      deviance        0.50           5        80  0.795200\n",
      "34      deviance        0.50           4       120  0.795400\n",
      "31      deviance        0.50           4        90  0.796733\n",
      "8       deviance        1.00           3       110  0.797267\n",
      "33      deviance        0.50           4       110  0.798333\n",
      "128  exponential        1.00           3       110  0.798400\n",
      "133  exponential        1.00           4       110  0.798733\n",
      "32      deviance        0.50           4       100  0.799600\n",
      "131  exponential        1.00           4        90  0.800000\n",
      "136  exponential        1.00           5        90  0.800600\n",
      "132  exponential        1.00           4       100  0.801533\n",
      "..           ...         ...         ...       ...       ...\n",
      "105     deviance        0.05           3        80  0.863067\n",
      "101     deviance        0.05           2        90  0.863200\n",
      "236  exponential        0.05           5        90  0.863267\n",
      "102     deviance        0.05           2       100  0.863267\n",
      "103     deviance        0.05           2       110  0.863400\n",
      "229  exponential        0.05           3       120  0.863467\n",
      "228  exponential        0.05           3       110  0.863467\n",
      "204  exponential        0.10           2       120  0.863467\n",
      "234  exponential        0.05           4       120  0.863533\n",
      "238  exponential        0.05           5       110  0.863533\n",
      "202  exponential        0.10           2       100  0.863533\n",
      "239  exponential        0.05           5       120  0.863600\n",
      "237  exponential        0.05           5       100  0.863600\n",
      "224  exponential        0.05           2       120  0.863600\n",
      "231  exponential        0.05           4        90  0.863600\n",
      "235  exponential        0.05           5        80  0.863667\n",
      "200  exponential        0.10           2        80  0.863667\n",
      "220  exponential        0.05           2        80  0.863667\n",
      "221  exponential        0.05           2        90  0.863667\n",
      "226  exponential        0.05           3        90  0.863667\n",
      "225  exponential        0.05           3        80  0.863667\n",
      "222  exponential        0.05           2       100  0.863667\n",
      "230  exponential        0.05           4        80  0.863667\n",
      "232  exponential        0.05           4       100  0.863733\n",
      "233  exponential        0.05           4       110  0.863733\n",
      "223  exponential        0.05           2       110  0.863733\n",
      "100     deviance        0.05           2        80  0.863733\n",
      "227  exponential        0.05           3       100  0.863800\n",
      "203  exponential        0.10           2       110  0.863800\n",
      "201  exponential        0.10           2        90  0.864000\n",
      "\n",
      "[240 rows x 5 columns]\n",
      "----\n",
      "count    240.000000\n",
      "mean       0.837538\n",
      "std        0.027143\n",
      "min        0.741133\n",
      "25%        0.822233\n",
      "50%        0.848400\n",
      "75%        0.859800\n",
      "max        0.864000\n",
      "Name: score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dfModels = pd.read_csv('gbm_test_model_scores.csv', index_col=0)\n",
    "dfModels.sort_values(by=['score'], inplace=True)\n",
    "\n",
    "print(dfModels)\n",
    "print('----')\n",
    "print(dfModels['score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some trends are immediately obvious: models with lower learning rates and exponential loss functions perform better. It seems that shallower trees also produce better performance, but the effect of tree number is not as clear. \n",
    "\n",
    "Now we train the worst and best 10 models on the full data set and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loss  learn_rate  tree_depth  tree_num     score\n",
      "16  deviance         1.0           5        90  0.741133\n",
      "18  deviance         1.0           5       110  0.758333\n",
      "10  deviance         1.0           4        80  0.759200\n",
      "12  deviance         1.0           4       100  0.764400\n",
      "15  deviance         1.0           5        80  0.765267\n",
      "19  deviance         1.0           5       120  0.766400\n",
      "14  deviance         1.0           4       120  0.770333\n",
      "11  deviance         1.0           4        90  0.774400\n",
      "5   deviance         1.0           3        80  0.777733\n",
      "17  deviance         1.0           5       100  0.777733\n",
      "            loss  learn_rate  tree_depth  tree_num     score\n",
      "225  exponential        0.05           3        80  0.863667\n",
      "222  exponential        0.05           2       100  0.863667\n",
      "230  exponential        0.05           4        80  0.863667\n",
      "232  exponential        0.05           4       100  0.863733\n",
      "233  exponential        0.05           4       110  0.863733\n",
      "223  exponential        0.05           2       110  0.863733\n",
      "100     deviance        0.05           2        80  0.863733\n",
      "227  exponential        0.05           3       100  0.863800\n",
      "203  exponential        0.10           2       110  0.863800\n",
      "201  exponential        0.10           2        90  0.864000\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate           1\n",
      "tree_depth           5\n",
      "tree_num            90\n",
      "score         0.741133\n",
      "Name: 16, dtype: object\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate           1\n",
      "tree_depth           5\n",
      "tree_num           110\n",
      "score         0.758333\n",
      "Name: 18, dtype: object\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate           1\n",
      "tree_depth           4\n",
      "tree_num            80\n",
      "score           0.7592\n",
      "Name: 10, dtype: object\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate           1\n",
      "tree_depth           4\n",
      "tree_num           100\n",
      "score           0.7644\n",
      "Name: 12, dtype: object\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate           1\n",
      "tree_depth           5\n",
      "tree_num            80\n",
      "score         0.765267\n",
      "Name: 15, dtype: object\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate           1\n",
      "tree_depth           5\n",
      "tree_num           120\n",
      "score           0.7664\n",
      "Name: 19, dtype: object\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate           1\n",
      "tree_depth           4\n",
      "tree_num           120\n",
      "score         0.770333\n",
      "Name: 14, dtype: object\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate           1\n",
      "tree_depth           4\n",
      "tree_num            90\n",
      "score           0.7744\n",
      "Name: 11, dtype: object\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate           1\n",
      "tree_depth           3\n",
      "tree_num            80\n",
      "score         0.777733\n",
      "Name: 5, dtype: object\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate           1\n",
      "tree_depth           5\n",
      "tree_num           100\n",
      "score         0.777733\n",
      "Name: 17, dtype: object\n",
      "Computing row:\n",
      "loss          exponential\n",
      "learn_rate           0.05\n",
      "tree_depth              3\n",
      "tree_num               80\n",
      "score            0.863667\n",
      "Name: 225, dtype: object\n",
      "Computing row:\n",
      "loss          exponential\n",
      "learn_rate           0.05\n",
      "tree_depth              2\n",
      "tree_num              100\n",
      "score            0.863667\n",
      "Name: 222, dtype: object\n",
      "Computing row:\n",
      "loss          exponential\n",
      "learn_rate           0.05\n",
      "tree_depth              4\n",
      "tree_num               80\n",
      "score            0.863667\n",
      "Name: 230, dtype: object\n",
      "Computing row:\n",
      "loss          exponential\n",
      "learn_rate           0.05\n",
      "tree_depth              4\n",
      "tree_num              100\n",
      "score            0.863733\n",
      "Name: 232, dtype: object\n",
      "Computing row:\n",
      "loss          exponential\n",
      "learn_rate           0.05\n",
      "tree_depth              4\n",
      "tree_num              110\n",
      "score            0.863733\n",
      "Name: 233, dtype: object\n",
      "Computing row:\n",
      "loss          exponential\n",
      "learn_rate           0.05\n",
      "tree_depth              2\n",
      "tree_num              110\n",
      "score            0.863733\n",
      "Name: 223, dtype: object\n",
      "Computing row:\n",
      "loss          deviance\n",
      "learn_rate        0.05\n",
      "tree_depth           2\n",
      "tree_num            80\n",
      "score         0.863733\n",
      "Name: 100, dtype: object\n",
      "Computing row:\n",
      "loss          exponential\n",
      "learn_rate           0.05\n",
      "tree_depth              3\n",
      "tree_num              100\n",
      "score              0.8638\n",
      "Name: 227, dtype: object\n",
      "Computing row:\n",
      "loss          exponential\n",
      "learn_rate            0.1\n",
      "tree_depth              2\n",
      "tree_num              110\n",
      "score              0.8638\n",
      "Name: 203, dtype: object\n",
      "Computing row:\n",
      "loss          exponential\n",
      "learn_rate            0.1\n",
      "tree_depth              2\n",
      "tree_num               90\n",
      "score               0.864\n",
      "Name: 201, dtype: object\n",
      "----\n",
      "Scores on larger data:\n",
      "            loss  learn_rate  tree_depth  tree_num     score  full_score\n",
      "16      deviance        1.00           5        90  0.741133     0.81065\n",
      "18      deviance        1.00           5       110  0.758333     0.79330\n",
      "10      deviance        1.00           4        80  0.759200     0.82730\n",
      "12      deviance        1.00           4       100  0.764400     0.82025\n",
      "15      deviance        1.00           5        80  0.765267     0.79835\n",
      "19      deviance        1.00           5       120  0.766400     0.79555\n",
      "14      deviance        1.00           4       120  0.770333     0.80210\n",
      "11      deviance        1.00           4        90  0.774400     0.82110\n",
      "5       deviance        1.00           3        80  0.777733     0.83485\n",
      "17      deviance        1.00           5       100  0.777733     0.80400\n",
      "225  exponential        0.05           3        80  0.863667     0.86530\n",
      "222  exponential        0.05           2       100  0.863667     0.86530\n",
      "230  exponential        0.05           4        80  0.863667     0.86530\n",
      "232  exponential        0.05           4       100  0.863733     0.86530\n",
      "233  exponential        0.05           4       110  0.863733     0.86530\n",
      "223  exponential        0.05           2       110  0.863733     0.86530\n",
      "100     deviance        0.05           2        80  0.863733     0.86530\n",
      "227  exponential        0.05           3       100  0.863800     0.86530\n",
      "203  exponential        0.10           2       110  0.863800     0.86525\n",
      "201  exponential        0.10           2        90  0.864000     0.86530\n"
     ]
    }
   ],
   "source": [
    "train_sample = train.sample(n=20000, replace=False)\n",
    "test_sample = test.sample(n=20000, replace=False)\n",
    "\n",
    "X_train, X_test = train_sample[X_cols], test_sample[X_cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train, y_test = train_sample.Default, test_sample.Default\n",
    "\n",
    "dfModels = pd.read_csv('gbm_test_model_scores.csv', index_col=0)\n",
    "dfModels.sort_values(by=['score'], inplace=True)\n",
    "\n",
    "dfWorst = dfModels.iloc[:10]\n",
    "dfBest = dfModels.iloc[-10:]\n",
    "\n",
    "print(dfWorst)\n",
    "print(dfBest)\n",
    "\n",
    "def scoreFromRow(row):\n",
    "    print('Computing row:')\n",
    "    print(row)\n",
    "    gbm = GBModel(row.loss, row.learn_rate, row.tree_depth, row.tree_num)\n",
    "    return gbm.score\n",
    "\n",
    "dfBoth = pd.concat([dfWorst, dfBest])\n",
    "dfBoth['full_score'] = dfBoth.apply(scoreFromRow, axis=1)\n",
    "\n",
    "print('----')\n",
    "print('Scores on larger data:')\n",
    "print(dfBoth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case there was a tie for the top-scoring models on the larger test set, so we train the top 3 models on the full data set and use the one with the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of final Gradient Boosting model:\n",
      "{'loss': 'exponential', 'learn_rate': 0.05, 'tree_depth': 2, 'tree_num': 100, 'score': 0.8651190682847539}\n",
      "Accuracy of final Gradient Boosting model: 0.8651190682847539\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train[X_cols], test[X_cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train, y_test = train.Default, test.Default\n",
    "\n",
    "gbms = [\n",
    "    GBModel('exponential', 0.05, 2, 100),\n",
    "    GBModel('exponential', 0.10, 2, 110),\n",
    "    GBModel('exponential', 0.10, 3, 90)\n",
    "]\n",
    "gbms = sorted(gbms, key=lambda x: x.score)\n",
    "best_gbm = gbms[-1]\n",
    "print('Parameters of final Gradient Boosting model:')\n",
    "print(best_gbm.rowDict)\n",
    "print('Accuracy of final Gradient Boosting model: ' + str(best_gbm.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked model\n",
    "\n",
    "This model uses the prediction of the Logistic Regression model as a feature in a new Gradient Boosting classifier. The simplest way to implement this is to simply add the predictions from the Logistic Regression model to the data sets and repeat the above steps to choose a new Gradient Boosting classifier. For simplicity, we'll just check the top 10 Gradient Boosting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8653\n",
      "Score: 0.8653\n",
      "Score: 0.8653\n",
      "Score: 0.8654\n",
      "Score: 0.8653\n",
      "Score: 0.8653\n",
      "Score: 0.8653\n",
      "Score: 0.86535\n",
      "Score: 0.8652\n",
      "Score: 0.86535\n",
      "            loss  learn_rate  tree_depth  tree_num     score  stacked_score\n",
      "225  exponential        0.05           3        80  0.863667        0.86530\n",
      "222  exponential        0.05           2       100  0.863667        0.86530\n",
      "230  exponential        0.05           4        80  0.863667        0.86530\n",
      "232  exponential        0.05           4       100  0.863733        0.86540\n",
      "233  exponential        0.05           4       110  0.863733        0.86530\n",
      "223  exponential        0.05           2       110  0.863733        0.86530\n",
      "100     deviance        0.05           2        80  0.863733        0.86530\n",
      "227  exponential        0.05           3       100  0.863800        0.86535\n",
      "203  exponential        0.10           2       110  0.863800        0.86520\n",
      "201  exponential        0.10           2        90  0.864000        0.86535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "N = len(dfBest.index)\n",
    "stackedScores = []\n",
    "for i in range(N):\n",
    "    row = dfBest.iloc[i]\n",
    "    \n",
    "    # Get data to feed into log regression\n",
    "    X_train, X_test = train_sample[X_cols], test_sample[X_cols]\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_train, y_test = train_sample.Default, test_sample.Default\n",
    "\n",
    "    # Fit log regression\n",
    "    logModel = LogisticRegression(penalty='l1', C=0.015).fit(X_train, y_train)\n",
    "\n",
    "    # Append predictions to train/test, scale\n",
    "    X_train, X_test = train_sample[X_cols], test_sample[X_cols]\n",
    "    X_train['log_prediction'] = logModel.predict(X_train)\n",
    "    X_test['log_prediction'] = logModel.predict(X_test)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit GB model using new feature\n",
    "    gbModel = GradientBoostingClassifier(\n",
    "        loss=row.loss,\n",
    "        learning_rate=row.learn_rate,\n",
    "        n_estimators=row.tree_num,\n",
    "        subsample=0.5,\n",
    "        max_depth=row.tree_depth\n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "    score = gbModel.score(X_test, y_test)\n",
    "    print('Score: ' + str(score))\n",
    "    stackedScores.append(score)\n",
    "    \n",
    "dfBest['stacked_score'] = stackedScores\n",
    "print(dfBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8651190682847539\n",
      "Score: 0.8650638344879827\n",
      "Score: 0.8651190682847539\n"
     ]
    }
   ],
   "source": [
    "bestGbms = [\n",
    "    {'loss': 'deviance', 'learn': 0.05, 'depth': 2, 'num': 90},\n",
    "    {'loss': 'exponential', 'learn': 0.10, 'depth': 3, 'num': 90},\n",
    "    {'loss': 'exponential', 'learn': 0.05, 'depth': 2, 'num': 100},\n",
    "]\n",
    "for gbm in bestGbms:\n",
    "    \n",
    "    # Get data to feed into log regression\n",
    "    X_train, X_test = train[X_cols], test[X_cols]\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_train, y_test = train.Default, test.Default\n",
    "\n",
    "    # Fit log regression\n",
    "    logModel = LogisticRegression(penalty='l1', C=0.015).fit(X_train, y_train)\n",
    "\n",
    "    # Append predictions to train/test, scale\n",
    "    X_train, X_test = train[X_cols], test[X_cols]\n",
    "    X_train['log_prediction'] = logModel.predict(X_train)\n",
    "    X_test['log_prediction'] = logModel.predict(X_test)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit GB model using new feature\n",
    "    gbModel = GradientBoostingClassifier(\n",
    "        loss=gbm['loss'],\n",
    "        learning_rate=gbm['learn'],\n",
    "        n_estimators=gbm['num'],\n",
    "        subsample=0.5,\n",
    "        max_depth=gbm['depth']\n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "    score = gbModel.score(X_test, y_test)\n",
    "    print('Score: ' + str(score))\n",
    "    gbm['score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': 'deviance', 'learn': 0.05, 'depth': 2, 'num': 90, 'score': 0.8651190682847539}, {'loss': 'exponential', 'learn': 0.1, 'depth': 3, 'num': 90, 'score': 0.8651032871999621}, {'loss': 'exponential', 'learn': 0.05, 'depth': 2, 'num': 100, 'score': 0.8651190682847539}]\n",
      "Accuracy of best stacked model (first attempt): 0.8651190682847539\n"
     ]
    }
   ],
   "source": [
    "print(bestGbms)\n",
    "bestGbms = sorted(bestGbms, key=lambda x: x['score'])\n",
    "print('Accuracy of best stacked model (first attempt): ' + str(bestGbms[-1]['score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our stacked model failed to produce an increase in accuracy over the best Gradient Boosting model. One problem could be that the linear model and the Gradient Boosting model both train with the same data. Instead, we can try randomly splitting the data in half and having each model train on a different half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8653\n",
      "Score: 0.8653\n",
      "Score: 0.8653\n",
      "Score: 0.8653\n",
      "Score: 0.86525\n",
      "Score: 0.8653\n",
      "Score: 0.8653\n",
      "Score: 0.8653\n",
      "Score: 0.86525\n",
      "Score: 0.8653\n",
      "            loss  learn_rate  tree_depth  tree_num     score  stacked_score  \\\n",
      "225  exponential        0.05           3        80  0.863667        0.86530   \n",
      "222  exponential        0.05           2       100  0.863667        0.86530   \n",
      "230  exponential        0.05           4        80  0.863667        0.86530   \n",
      "232  exponential        0.05           4       100  0.863733        0.86540   \n",
      "233  exponential        0.05           4       110  0.863733        0.86530   \n",
      "223  exponential        0.05           2       110  0.863733        0.86530   \n",
      "100     deviance        0.05           2        80  0.863733        0.86530   \n",
      "227  exponential        0.05           3       100  0.863800        0.86535   \n",
      "203  exponential        0.10           2       110  0.863800        0.86520   \n",
      "201  exponential        0.10           2        90  0.864000        0.86535   \n",
      "\n",
      "     stacked_score_2  \n",
      "225          0.86530  \n",
      "222          0.86530  \n",
      "230          0.86530  \n",
      "232          0.86530  \n",
      "233          0.86525  \n",
      "223          0.86530  \n",
      "100          0.86530  \n",
      "227          0.86530  \n",
      "203          0.86525  \n",
      "201          0.86530  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Shuffle then split training data\n",
    "train_sample = shuffle(train)\n",
    "S = len(train_sample.index)\n",
    "train_sample_1 = train_sample.iloc[:math.floor(S/2)]\n",
    "train_sample_2 = train_sample.iloc[math.floor(S/2):]\n",
    "\n",
    "N = len(dfBest.index)\n",
    "stackedScores2 = []\n",
    "for i in range(N):\n",
    "    row = dfBest.iloc[i]\n",
    "    \n",
    "    # Get data to feed into log regression (from train_sample_1)\n",
    "    X_train, X_test = train_sample_1[X_cols], test_sample[X_cols]\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_train, y_test = train_sample_1.Default, test_sample.Default\n",
    "\n",
    "    # Fit log regression\n",
    "    logModel = LogisticRegression(penalty='l1', C=0.015).fit(X_train, y_train)\n",
    "\n",
    "    # Append predictions to train/test for GB model (train_sample_2)\n",
    "    X_train, X_test = train_sample_2[X_cols], test_sample[X_cols]\n",
    "    X_train['log_prediction'] = logModel.predict(X_train)\n",
    "    X_test['log_prediction'] = logModel.predict(X_test)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_train, y_test = train_sample_2.Default, test_sample.Default\n",
    "\n",
    "    # Fit GB model using new feature\n",
    "    gbModel = GradientBoostingClassifier(\n",
    "        loss=row.loss,\n",
    "        learning_rate=row.learn_rate,\n",
    "        n_estimators=row.tree_num,\n",
    "        subsample=0.5,\n",
    "        max_depth=row.tree_depth\n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    score = gbModel.score(X_test, y_test)\n",
    "    print('Score: ' + str(score))\n",
    "    stackedScores2.append(score)\n",
    "    \n",
    "dfBest['stacked_score_2'] = stackedScores2\n",
    "print(dfBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of best stacked model (2nd attempt): 0.86455\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of best stacked model (2nd attempt): ' + str(max(dfBest.stacked_score_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately this change resulted in slightly worse models. Therefore we will preserve the first attempt as our best stacked model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Wreath\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of selected stacked model: 0.8651190682847539\n"
     ]
    }
   ],
   "source": [
    "# Data for log regression\n",
    "X_train, X_test = train[X_cols], test[X_cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train, y_test = train.Default, test.Default\n",
    "\n",
    "# Fit log regression\n",
    "logModel = LogisticRegression(penalty='l1', C=0.015).fit(X_train, y_train)\n",
    "\n",
    "# Append predictions to train/test for GB model (train_sample_2)\n",
    "X_train, X_test = train[X_cols], test[X_cols]\n",
    "X_train['log_prediction'] = logModel.predict(X_train)\n",
    "X_test['log_prediction'] = logModel.predict(X_test)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train, y_test = train.Default, test.Default\n",
    "\n",
    "gbm = GradientBoostingClassifier(\n",
    "    loss='exponential', learning_rate=0.05, n_estimators=100, subsample=0.5, max_depth=2\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# Save stacked model predictions for later\n",
    "stackedPredictions = gbm.predict(X_test)\n",
    "\n",
    "print('Accuracy of selected stacked model: ' + str(gbm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blended model\n",
    "\n",
    "Another way to combine models is by taking a weighted average of votes from a collection of models. We use strong and weak versions of the logistic regression, k-nearest neighbors, and gradient boosting models as the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for base model predictions\n",
    "X_train, X_test = train[X_cols], test[X_cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train, y_test = train.Default, test.Default\n",
    "\n",
    "# Selected base models\n",
    "baseModels = [\n",
    "    LogisticRegression(penalty='l2', C=0.7),\n",
    "    LogisticRegression(penalty='l1', C=0.015),\n",
    "    GradientBoostingClassifier(\n",
    "        loss='deviance', learning_rate=1, n_estimators=120, subsample=0.5, max_depth=5\n",
    "    ),\n",
    "    GradientBoostingClassifier(\n",
    "        loss='exponential', learning_rate=0.05, n_estimators=100, subsample=0.5, max_depth=2\n",
    "    ),\n",
    "    KNeighborsClassifier(n_neighbors=12, metric='minkowski', p=2, weights='uniform'),\n",
    "    KNeighborsClassifier(n_neighbors=19, metric='chebyshev', weights='distance')\n",
    "]\n",
    "N = len(baseModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models, get predictions\n",
    "print('Training base models')\n",
    "baseModels_trained = []\n",
    "for m in enumerate(baseModels):\n",
    "    baseModels_trained.append(m.fit(X_train, y_train))\n",
    "baseModels = \n",
    "print('Getting base model predictions')\n",
    "baseTrainPredictions = [m.predict(X_train) for m in baseModels]\n",
    "baseTestPredictions = [m.predict(X_test) for m in baseModels]\n",
    "\n",
    "# Data for exterior model\n",
    "print('Saving')\n",
    "train_ext = pd.DataFrame()\n",
    "for i, col in enumerate(baseTrainPredictions):\n",
    "    train_ext['model_'+str(i)] = col\n",
    "train_ext['Default'] = train['Default'].astype('int').values\n",
    "    \n",
    "test_ext = pd.DataFrame()\n",
    "for i, col in enumerate(baseTestPredictions):\n",
    "    test_ext['model_'+str(i)] = col\n",
    "test_ext['Default'] = test['Default'].astype('int').values\n",
    "\n",
    "train_ext.to_csv('blended_data_train.csv')\n",
    "test_ext.to_csv('blended_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "Optimal weights:\n",
      "[0.16674805 0.17626954 0.16674805 0.16674805 0.15673827 0.16674805]\n",
      "Score:\n",
      "0.8651269588271497\n"
     ]
    }
   ],
   "source": [
    "train_ext = pd.read_csv('blended_data_train.csv', index_col=0)\n",
    "test_ext = pd.read_csv('blended_data_test.csv', index_col=0)\n",
    "\n",
    "X_cols_ext = [c for c in train_ext.columns if not c=='Default']\n",
    "X_train, X_test = train_ext[X_cols_ext], test_ext[X_cols_ext]\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train, y_test = train_ext.Default, test_ext.Default\n",
    "\n",
    "# Optimize weights\n",
    "def neg_score(weights):\n",
    "    # To predict: for each row, multiply weights by row values and check if > 0.5\n",
    "    ext_predictions = np.apply_along_axis(lambda x: sum(weights*x) > 0.5, 1, X_test)\n",
    "    return -sum(np.equal(ext_predictions, y_test))/len(y_test)\n",
    "\n",
    "# Minimize function neg_score over all possible weights\n",
    "N = len(baseModels)\n",
    "optResult = minimize(\n",
    "    fun = neg_score,\n",
    "    x0 = [1/N]*N,  #initial guess: uniform weights\n",
    "    method = 'SLSQP',\n",
    "    bounds = [(-10, 10)]*N,  #bounds on weights (no reason for magnitude > 10)\n",
    "    constraints = [\n",
    "        {'type': 'eq', 'fun': lambda x: sum(x)-1}  #weights sum to 1\n",
    "    ]\n",
    ")\n",
    "\n",
    "def test_score(weights):\n",
    "    ext_predictions = np.apply_along_axis(lambda x: sum(weights*x) > 0.5, 1, X_test)\n",
    "    return sum(np.equal(ext_predictions, y_test))/len(y_test)\n",
    "\n",
    "print(optResult.message)\n",
    "if optResult.success:\n",
    "    print('Optimal weights:')\n",
    "    print(optResult.x)\n",
    "    print('Score:')\n",
    "    print(test_score(optResult.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This blended model is not an improvement over the best individual model. In fact, we can try many different initial values and optimization will never improve performance over the best base model. This is because the input is really categorical: each model predits either 0 or 1 and there are 6 models, hence there are $2^6 = 64$ inputs. The weighted average is simply a way to map each of these 64 inputs to a prediction (0 or 1).\n",
    "\n",
    "It's possible that we could fix this by increasing the number of models, creating more possible functions for the optimization procedure to move through so that it could approach a better function by small steps. Instead, we build our own prediction system which computes the probability of default given a particular input string and returns 1 if that probability is greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allBinaryStrings(n):\n",
    "    \"\"\"Return all binary strings of length n (as list of lists of bits)\"\"\"\n",
    "    if n > 1:\n",
    "        return [[0]+s for s in allBinaryStrings(n-1)] + [[1]+s for s in allBinaryStrings(n-1)]\n",
    "    else:\n",
    "        return [[0], [1]]\n",
    "\n",
    "    \n",
    "class BinaryStringClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Set dimensions\n",
    "        self.inputLength = X.shape[1]\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise Exception('Shape mismatch: ' + str(X.shape) + ' ' + str(y.shape))\n",
    "        # Create counting dict (initialize with all binary strings)\n",
    "        bStrings = allBinaryStrings(self.inputLength)\n",
    "        bStrings = [''.join([str(int(t)) for t in bStr]) for bStr in bStrings]\n",
    "        self.counts = {\n",
    "            bStr: {'true_count': 0, 'total': 0, 'prob': 0} \n",
    "            for bStr in bStrings\n",
    "        }\n",
    "        # Fill dict, store count == 1 and total count\n",
    "        X_bStrings = np.apply_along_axis(lambda x: ''.join([str(int(t)) for t in x]), 1, X)\n",
    "        for bStr, yy in zip(X_bStrings, y):\n",
    "            self.counts[bStr]['total'] += 1\n",
    "            if yy == 1:\n",
    "                self.counts[bStr]['true_count'] += 1\n",
    "        # Compute probabilities, predictMap\n",
    "        self.predictMap = {bStr: 0 for bStr in bStrings}\n",
    "        for bStr, store in self.counts.items():\n",
    "            if store['total'] > 0:\n",
    "                store['prob'] = store['true_count']/store['total']\n",
    "            if store['prob'] > 0.5:\n",
    "                self.predictMap[bStr] = 1        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return predicted values for rows of X\"\"\"\n",
    "        if X.shape[1] != self.inputLength:\n",
    "            raise Exception('Bad input length: ' + str(X.shape) + ', need ' + str(self.inputLength))\n",
    "        return np.apply_along_axis(\n",
    "            lambda x: self.predictMap[ ''.join([str(int(t)) for t in x]) ], 1, X\n",
    "        )\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Return accuracy of predictions for X compared to y\"\"\"\n",
    "        if X.shape[1] != self.inputLength:\n",
    "            raise Exception('Bad input length: ' + str(X.shape) + ', need ' + str(self.inputLength))\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise Exception('Shape mismatch: ' + str(X.shape) + ' ' + str(y.shape))\n",
    "        return sum(np.equal(self.predict(X), y))/len(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8649218047248568"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ext = pd.read_csv('blended_data_train.csv', index_col=0)\n",
    "test_ext = pd.read_csv('blended_data_test.csv', index_col=0)\n",
    "\n",
    "X_cols_ext = [c for c in train_ext.columns if not c=='Default']\n",
    "X_train, X_test = train_ext[X_cols_ext], test_ext[X_cols_ext]\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train, y_test = train_ext.Default, test_ext.Default\n",
    "\n",
    "bsc = BinaryStringClassifier()\n",
    "bsc.fit(X_train, y_train)\n",
    "bsc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier performs slightly worse than the best base model. I think we can attribute this to overfitting: the model relies solely on the probability of default given an input string based solely on the probability meaured from the training data. A modification to this approach would be to have the model continuously update the counts and probability for each new test input it makes, and use this data in further inputs. Thus, the model trains itself after each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryStringUpdateClassifier(BinaryStringClassifier):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def predictAndUpdate(self, X_row, y_val):\n",
    "        \"\"\"Make prediction for X_row, update model, and return prediction\"\"\"\n",
    "        bStr = ''.join([str(int(t)) for t in X_row])\n",
    "        prediction = self.predictMap[bStr]\n",
    "        store = self.counts[bStr]\n",
    "        store['total'] += 1\n",
    "        if y_val == 1:\n",
    "            store['true_count'] += 1\n",
    "        store['prob'] = store['true_count']/store['total']\n",
    "        self.counts[bStr] = store\n",
    "        if store['prob'] > 0.5:\n",
    "            self.predictMap[bStr] = 1\n",
    "        else:\n",
    "            self.predictMap[bStr] = 0\n",
    "        return prediction\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Return predicted values for rows of X; update model after each prediction\"\"\"\n",
    "        if X.shape[1] != self.inputLength:\n",
    "            raise Exception('Bad input length: ' + str(X.shape) + ', need ' + str(self.inputLength))\n",
    "        predictions = [self.predictAndUpdate(X[i], y[i]) for i in range(X.shape[0])]\n",
    "        return {'score': sum(np.equal(predictions, y))/len(y), 'predictions': predictions} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8649218047248568\n"
     ]
    }
   ],
   "source": [
    "bsc = BinaryStringUpdateClassifier()\n",
    "bsc.fit(X_train, y_train)\n",
    "print(bsc.score(X_test, y_test)['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the update mechanism was tested and works as expected, it did not change the predictions. This is probably because the effect is too weak, i.e. the probability is too heavily weighted by past values. So instead, we will give new values more weight when updating the model by having them directly \"pull\" the probability toward 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryStringUpdateClassifier(BinaryStringClassifier):\n",
    "    def __init__(self, inverseUpdateWeight):\n",
    "        super().__init__()\n",
    "        if inverseUpdateWeight < 1:\n",
    "            raise Exception('inverseUpdateWeight must be >= 1 (was ' + str(inverseUpdateWeight) + ')')\n",
    "        self.inverseUpdateWeight = inverseUpdateWeight\n",
    "        \n",
    "    def predictAndUpdate(self, X_row, y_val):\n",
    "        \"\"\"Make prediction for X_row, update model, and return prediction\"\"\"\n",
    "        bStr = ''.join([str(int(t)) for t in X_row])\n",
    "        prediction = self.predictMap[bStr]\n",
    "        store = self.counts[bStr]\n",
    "        w = self.inverseUpdateWeight\n",
    "        if y_val == 1:\n",
    "            store['prob'] = store['prob'] + (1 - store['prob'])/w\n",
    "        else:\n",
    "            store['prob'] = store['prob'] + (0 - store['prob'])/w\n",
    "        self.counts[bStr] = store\n",
    "        if store['prob'] > 0.5:\n",
    "            self.predictMap[bStr] = 1\n",
    "        else:\n",
    "            self.predictMap[bStr] = 0\n",
    "        return prediction\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Return predicted values for rows of X; update model after each prediction\"\"\"\n",
    "        if X.shape[1] != self.inputLength:\n",
    "            raise Exception('Bad input length: ' + str(X.shape) + ', need ' + str(self.inputLength))\n",
    "        predictions = [self.predictAndUpdate(X[i], y[i]) for i in range(X.shape[0])]\n",
    "        return {'score': sum(np.equal(predictions, y))/len(y), 'predictions': predictions} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse update weight: 1\n",
      "Inverse update weight: 2\n",
      "Inverse update weight: 3\n",
      "Inverse update weight: 4\n",
      "Inverse update weight: 5\n",
      "Inverse update weight: 6\n",
      "Inverse update weight: 7\n",
      "Inverse update weight: 8\n",
      "Inverse update weight: 9\n",
      "Inverse update weight: 10\n",
      "Inverse update weight: 11\n",
      "Inverse update weight: 12\n",
      "Inverse update weight: 13\n",
      "Inverse update weight: 14\n",
      "Inverse update weight: 15\n",
      "Inverse update weight: 16\n",
      "Inverse update weight: 17\n",
      "Inverse update weight: 18\n",
      "Inverse update weight: 19\n",
      "Inverse update weight: 20\n",
      "Optimal weight/score:\n",
      "(13, 0.8650322723183992)\n"
     ]
    }
   ],
   "source": [
    "optimalWeight = (1, 0.0)\n",
    "for weight in range(1, 21):\n",
    "    print('Inverse update weight: ' + str(weight))\n",
    "    bsc = BinaryStringUpdateClassifier(weight)\n",
    "    bsc.fit(X_train, y_train)\n",
    "    score = bsc.score(X_test, y_test)['score']\n",
    "    if score > optimalWeight[1]:\n",
    "        optimalWeight = (weight, score)\n",
    "\n",
    "print('Optimal weight/score:')\n",
    "print(optimalWeight)\n",
    "\n",
    "# Save predictions for later\n",
    "bsc = BinaryStringUpdateClassifier(optimalWeight[0])\n",
    "bsc.fit(X_train, y_train)\n",
    "blendedPredictions = bsc.score(X_test, y_test)['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new update mechanism squeezed a little bit more accuracy out of the model, but unfortunately does not quite match the performance of the best base model (about .8651).\n",
    "\n",
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models\n",
      "Predictions\n",
      "Knn predictions\n",
      "Gbm predictions\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Collect all models and their predictions, save to csv\n",
    "X_train, X_test = train[X_cols], test[X_cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train, y_test = train.Default, test.Default\n",
    "\n",
    "print('Fitting models')\n",
    "knnModel = KNeighborsClassifier(\n",
    "    n_neighbors=12,\n",
    "    metric='minkowski',\n",
    "    p=4,\n",
    "    weights='uniform'\n",
    ").fit(X_train, y_train)\n",
    "logModel = LogisticRegression(penalty='l1', C=0.015).fit(X_train, y_train)\n",
    "gbmModel = GradientBoostingClassifier(\n",
    "    loss='exponential',\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=100,\n",
    "    subsample=0.5,\n",
    "    max_depth=2\n",
    ").fit(X_train, y_train)\n",
    "# Already have stackedPredictions, blendedPredictions\n",
    "\n",
    "print('Predictions')\n",
    "dfPredictions = pd.DataFrame(columns=['knn', 'log', 'gbm', 'stacked', 'blended', 'y'])\n",
    "dfPredictions['stacked'] = stackedPredictions\n",
    "dfPredictions['blended'] = blendedPredictions\n",
    "dfPredictions['y'] = y_test.values\n",
    "dfPredictions['log'] = logModel.predict(X_test)\n",
    "print('Knn predictions')\n",
    "dfPredictions['knn'] = knnModel.predict(X_test)\n",
    "print('Gbm predictions')\n",
    "dfPredictions['gbm'] = gbmModel.predict(X_test)\n",
    "dfPredictions.to_csv('summary_predictions.csv')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  accuracy       tpr       fpr\n",
      "0  K-nearest neighbors  0.864646  0.001814  0.000830\n",
      "1  Logistic regression  0.865127  0.000059  0.000000\n",
      "2    Gradient boosting  0.865119  0.000000  0.000000\n",
      "3              Stacked  0.865119  0.000000  0.000000\n",
      "4              Blended  0.865032  0.000644  0.000201\n"
     ]
    }
   ],
   "source": [
    "dfPredictions = pd.read_csv('summary_predictions.csv', index_col=0)\n",
    "\n",
    "def modelMetrics(modelCode):\n",
    "    \"\"\"Return accuracy, true positive rate, false positive rate\"\"\"\n",
    "    y = dfPredictions['y'].values\n",
    "    mp = dfPredictions[modelCode].values\n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = sum(np.equal(mp, y))/len(y)\n",
    "    mp_posCheck = mp[np.where(y == 1)]\n",
    "    mp_negCheck = mp[np.where(y == 0)]\n",
    "    metrics['tpr'] = sum(mp_posCheck == 1)/len(mp_posCheck) # mp==1 when y==1\n",
    "    metrics['fpr'] = sum(mp_negCheck == 1)/len(mp_negCheck) # mp==1 when y==0\n",
    "    return metrics\n",
    "\n",
    "# Print table of model info\n",
    "dfComp = pd.DataFrame(columns=['model', 'accuracy', 'tpr', 'fpr'])\n",
    "models = ['K-nearest neighbors', 'Logistic regression', 'Gradient boosting', 'Stacked', 'Blended']\n",
    "codes = ['knn', 'log', 'gbm', 'stacked', 'blended']\n",
    "metrics = [modelMetrics(modelCode=c) for c in codes]\n",
    "for i, (model, metric) in enumerate(zip(models, metrics)):\n",
    "    dfComp.loc[i] = {\n",
    "        'model': model,\n",
    "        'accuracy': metric['accuracy'],\n",
    "        'tpr': metric['tpr'],\n",
    "        'fpr': metric['fpr']\n",
    "    }\n",
    "print(dfComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best (most accurate) model is the Logistic Regression model, with accuracy of 86.5127%. But the other models are extremely close: the K-Nearest Neighbors model has the lowest accuracy at 86.4646%.\n",
    "\n",
    "A final note: although we selected models to maximize accuracy, in some cases we may be interested in different performance metrics. For example, if we want to make sure the model detects most of the defaults, then we would prefer the K-nearest neighbors model, which has the highest true positive rate. If, furthermore, there is a significant cost associated to false positives, then we might prefer the Blended model, which has the highest ratio of true positives to false positives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
